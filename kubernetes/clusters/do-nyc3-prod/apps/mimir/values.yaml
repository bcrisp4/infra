# Mimir for do-nyc3-prod
# Uses DO Spaces for S3-compatible storage and Strimzi Kafka for ingest storage

externalSecret:
  enabled: true
  itemName: do-nyc3-prod-mimir-s3

kafka:
  enabled: true
  replicas: 3
  storageSize: 50Gi

# Tenant proxies for clients that cannot set X-Scope-OrgID header
# Each proxy is a simple nginx that adds the tenant header and forwards to mimir-gateway
tenantProxies:
  prod:
    tenant: prod
    replicas: 1

mimir-distributed:
  global:
    podAnnotations:
      prometheus.io/label-cluster: "mimir-do-nyc3-prod"

  mimir:
    structuredConfig:
      # Query frontend logging - log all queries
      frontend:
        log_queries_longer_than: -1s

      # Ingest storage configuration - use Strimzi Kafka
      ingest_storage:
        enabled: true
        kafka:
          address: mimir-kafka-kafka-bootstrap.mimir.svc.cluster.local:9092
          topic: mimir-ingest
          auto_create_topic_enabled: false

      # Common S3 storage configuration
      common:
        storage:
          backend: s3
          s3:
            bucket_name: ${S3_BUCKET}
            endpoint: ${S3_ENDPOINT}
            access_key_id: ${AWS_ACCESS_KEY_ID}
            secret_access_key: ${AWS_SECRET_ACCESS_KEY}
            http:
              idle_conn_timeout: 2m
              response_header_timeout: 5m
              max_idle_connections: 100
              max_idle_connections_per_host: 100

      # Block storage (metrics data)
      blocks_storage:
        backend: s3
        storage_prefix: blocks
        s3:
          bucket_name: ${S3_BUCKET}
          endpoint: ${S3_ENDPOINT}
          access_key_id: ${AWS_ACCESS_KEY_ID}
          secret_access_key: ${AWS_SECRET_ACCESS_KEY}
          http:
            idle_conn_timeout: 2m
            response_header_timeout: 5m
            max_idle_connections: 100
            max_idle_connections_per_host: 100

      # Alertmanager storage
      alertmanager_storage:
        backend: s3
        storage_prefix: alertmanager
        s3:
          bucket_name: ${S3_BUCKET}
          endpoint: ${S3_ENDPOINT}
          access_key_id: ${AWS_ACCESS_KEY_ID}
          secret_access_key: ${AWS_SECRET_ACCESS_KEY}
          http:
            idle_conn_timeout: 2m
            response_header_timeout: 5m
            max_idle_connections: 100
            max_idle_connections_per_host: 100

      # Ruler storage
      ruler_storage:
        backend: s3
        storage_prefix: ruler
        s3:
          bucket_name: ${S3_BUCKET}
          endpoint: ${S3_ENDPOINT}
          access_key_id: ${AWS_ACCESS_KEY_ID}
          secret_access_key: ${AWS_SECRET_ACCESS_KEY}
          http:
            idle_conn_timeout: 2m
            response_header_timeout: 5m
            max_idle_connections: 100
            max_idle_connections_per_host: 100

  # Runtime configuration with per-tenant overrides
  runtimeConfig:
    overrides:
      # Limits for "prod" tenant (X-Scope-OrgID: prod)
      prod:
        # Increase label limit for Istio metrics (default: 30, Istio has ~44)
        max_label_names_per_series: 60
        # Ingestion limits sized for current cluster capacity
        ingestion_rate: 100000
        ingestion_burst_size: 200000
        max_global_series_per_user: 1500000
        # Ruler limits for Mimir mixin rules
        ruler_max_rules_per_rule_group: 100
        ruler_max_rule_groups_per_tenant: 100

  # Alertmanager - HA with 2 replicas
  alertmanager:
    enabled: true
    replicas: 2
    persistentVolume:
      enabled: true
      size: 1Gi
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        memory: 256Mi
    statefulSet:
      enabled: true

  # Compactor
  compactor:
    replicas: 1
    persistentVolume:
      size: 50Gi
    resources:
      requests:
        cpu: 100m
        memory: 512Mi
      limits:
        memory: 1Gi

  # Distributor - sized for current cluster capacity
  distributor:
    replicas: 3
    podAnnotations:
      # Mark Kafka port as opaque for outbound connections
      config.linkerd.io/opaque-ports: "9092"
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        memory: 1Gi

  # Ingester - HA with 3 replicas
  ingester:
    replicas: 3
    podAnnotations:
      # Mark Kafka port as opaque for outbound connections
      config.linkerd.io/opaque-ports: "9092"
    persistentVolume:
      size: 10Gi
    resources:
      requests:
        cpu: 200m
        memory: 1Gi
      limits:
        memory: 3Gi
    zoneAwareReplication:
      enabled: false
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: app.kubernetes.io/component
                    operator: In
                    values:
                      - ingester
              topologyKey: kubernetes.io/hostname

  # Querier
  querier:
    replicas: 2
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        memory: 512Mi

  # Query Frontend
  query_frontend:
    replicas: 2
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        memory: 512Mi

  # Query Scheduler
  query_scheduler:
    replicas: 2
    resources:
      requests:
        cpu: 50m
        memory: 64Mi
      limits:
        memory: 128Mi

  # Store Gateway - HA with 3 replicas
  # Reduced memory - primarily reads from object storage
  store_gateway:
    replicas: 3
    persistentVolume:
      size: 5Gi
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        memory: 1024Mi
    zoneAwareReplication:
      enabled: false
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: app.kubernetes.io/component
                    operator: In
                    values:
                      - store-gateway
              topologyKey: kubernetes.io/hostname

  # Ruler
  ruler:
    enabled: true
    replicas: 1
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        memory: 256Mi

  # Overrides exporter
  overrides_exporter:
    replicas: 1
    resources:
      requests:
        cpu: 50m
        memory: 64Mi
      limits:
        memory: 128Mi

  # Gateway (nginx)
  gateway:
    replicas: 2
    resources:
      requests:
        cpu: 50m
        memory: 64Mi
      limits:
        memory: 128Mi

  # Caches
  chunks-cache:
    enabled: true
    replicas: 2
    allocatedMemory: 512
    resources:
      requests:
        cpu: 50m
        memory: 600Mi
      limits:
        memory: 600Mi

  index-cache:
    enabled: true
    replicas: 2
    allocatedMemory: 256
    resources:
      requests:
        cpu: 50m
        memory: 300Mi
      limits:
        memory: 300Mi

  metadata-cache:
    enabled: true
    replicas: 2
    allocatedMemory: 128
    resources:
      requests:
        cpu: 50m
        memory: 150Mi
      limits:
        memory: 150Mi

  results-cache:
    enabled: true
    replicas: 2
    allocatedMemory: 128
    resources:
      requests:
        cpu: 50m
        memory: 150Mi
      limits:
        memory: 150Mi
