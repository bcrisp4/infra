# otel-metrics for do-nyc3-prod
# OpenTelemetry Collector DaemonSet for scraping metrics and sending to Mimir
#
# Adapted for DOKS (DigitalOcean Kubernetes):
# - etcd scraping removed (managed by DO, not accessible)
# - kube-scheduler scraping removed (managed by DO, not accessible)
# - kubelet, cAdvisor, kube-apiserver all accessible

opentelemetry-collector:
  mode: daemonset

  image:
    repository: otel/opentelemetry-collector-contrib

  # Pod network (in Linkerd mesh)
  hostNetwork: false

  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      memory: 512Mi

  # Disable unused ports
  ports:
    otlp:
      enabled: false
    otlp-http:
      enabled: false
    jaeger-compact:
      enabled: false
    jaeger-thrift:
      enabled: false
    jaeger-grpc:
      enabled: false
    zipkin:
      enabled: false
    metrics:
      enabled: true
      containerPort: 8888
      servicePort: 8888
      protocol: TCP

  # RBAC for Kubernetes service discovery and kubelet metrics
  clusterRole:
    create: true
    rules:
      - apiGroups: [""]
        resources: ["pods", "nodes", "endpoints", "services"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["discovery.k8s.io"]
        resources: ["endpointslices"]
        verbs: ["get", "list", "watch"]
      # Required for scraping kubelet/cAdvisor metrics
      - apiGroups: [""]
        resources: ["nodes/metrics", "nodes/proxy"]
        verbs: ["get"]
      # Required for scraping apiserver /metrics endpoint
      - nonResourceURLs: ["/metrics"]
        verbs: ["get"]

  # Collector configuration
  config:
    receivers:
      # Scrape pods with prometheus.io/scrape=true annotation
      prometheus/annotations:
        config:
          scrape_configs:
            - job_name: "kubernetes-pods-annotations"
              scrape_interval: 30s
              kubernetes_sd_configs:
                - role: pod
              tls_config:
                insecure_skip_verify: true
              relabel_configs:
                # Set scheme (http/https) based on annotation
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
                  action: replace
                  target_label: __scheme__
                  regex: (https?)
                  replacement: $1
                # Only scrape pods on this node
                - source_labels: [__meta_kubernetes_pod_node_name]
                  action: keep
                  regex: ${env:K8S_NODE_NAME}
                # Only scrape pods with prometheus.io/scrape=true
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                  action: keep
                  regex: "true"
                # Use custom port if specified
                - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                  action: replace
                  regex: ([^:]+)(?::\d+)?;(\d+)
                  replacement: $1:$2
                  target_label: __address__
                # Use custom path if specified
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                  action: replace
                  target_label: __metrics_path__
                  regex: (.+)
                # Add namespace label
                - source_labels: [__meta_kubernetes_namespace]
                  action: replace
                  target_label: namespace
                # Add pod name label
                - source_labels: [__meta_kubernetes_pod_name]
                  action: replace
                  target_label: pod
                # Add container name label
                - source_labels: [__meta_kubernetes_pod_container_name]
                  action: replace
                  target_label: container
                # Add node name label
                - source_labels: [__meta_kubernetes_pod_node_name]
                  action: replace
                  target_label: node
                # Add app label (prefer app, fallback to app.kubernetes.io/name)
                - source_labels: [__meta_kubernetes_pod_label_app]
                  action: replace
                  target_label: app
                - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
                  action: replace
                  target_label: app
                  regex: (.+)
                # Override app for Tailscale proxies (default app label is UUID)
                - source_labels: [__meta_kubernetes_pod_label_tailscale_com_parent_resource]
                  action: replace
                  target_label: app
                  regex: (.+)
                  replacement: ts-$1
                # Add component label
                - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_component]
                  action: replace
                  target_label: component
                  regex: (.+)
                # Set job to namespace/app for uniqueness
                - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_app]
                  action: replace
                  target_label: job
                  separator: /
                  regex: (.+/.+)
                - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_app_kubernetes_io_name]
                  action: replace
                  target_label: job
                  separator: /
                  regex: (.+/.+)
                # Override job for Tailscale proxies (default app label is UUID)
                - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_tailscale_com_parent_resource]
                  action: replace
                  target_label: job
                  separator: /ts-
                  regex: (.+/ts-.+)
                # Extra labels from annotations (prometheus.io/label-<name>)
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_label_cluster]
                  action: replace
                  target_label: k8s_cluster
                  regex: (.+)
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_label_environment]
                  action: replace
                  target_label: environment
                  regex: (.+)
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_label_service]
                  action: replace
                  target_label: service
                  regex: (.+)
                # Set instance to node name for node-exporter (for cAdvisor join compatibility)
                - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name, __meta_kubernetes_pod_node_name]
                  action: replace
                  regex: prometheus-node-exporter;(.+)
                  replacement: $1
                  target_label: instance
              metric_relabel_configs:
                # Add k8s_cluster label to all metrics (avoids collision with CNPG's "cluster" label)
                - target_label: k8s_cluster
                  replacement: "do-nyc3-prod"
                  action: replace
                # Rename kube-state-metrics exported_* labels to standard names
                # KSM uses exported_namespace/pod/etc for the monitored resource's labels
                # while namespace/pod refer to the KSM pod itself
                # Only applies when job contains kube-state-metrics and exported_* label exists
                - source_labels: [job, exported_namespace]
                  regex: ".*/kube-state-metrics;(.+)"
                  target_label: namespace
                  replacement: "$1"
                  action: replace
                - source_labels: [job, exported_pod]
                  regex: ".*/kube-state-metrics;(.+)"
                  target_label: pod
                  replacement: "$1"
                  action: replace
                - source_labels: [job, exported_container]
                  regex: ".*/kube-state-metrics;(.+)"
                  target_label: container
                  replacement: "$1"
                  action: replace
                - source_labels: [job, exported_node]
                  regex: ".*/kube-state-metrics;(.+)"
                  target_label: node
                  replacement: "$1"
                  action: replace
                # Drop exported_* labels after copying
                - regex: "exported_(namespace|pod|container|node)"
                  action: labeldrop

      # Scrape pods with metrics-named ports (fallback discovery)
      prometheus/ports:
        config:
          scrape_configs:
            - job_name: "kubernetes-pods-metrics-ports"
              scrape_interval: 30s
              kubernetes_sd_configs:
                - role: pod
              relabel_configs:
                # Only scrape pods on this node
                - source_labels: [__meta_kubernetes_pod_node_name]
                  action: keep
                  regex: ${env:K8S_NODE_NAME}
                # Skip pods that have prometheus.io/scrape annotation (handled by other receiver)
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                  action: drop
                  regex: "true"
                # Skip pods that explicitly opt out
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                  action: drop
                  regex: "false"
                # Only keep targets with metrics-named ports
                - source_labels: [__meta_kubernetes_pod_container_port_name]
                  action: keep
                  regex: ".*metrics.*"
                # Add namespace label
                - source_labels: [__meta_kubernetes_namespace]
                  action: replace
                  target_label: namespace
                # Add pod name label
                - source_labels: [__meta_kubernetes_pod_name]
                  action: replace
                  target_label: pod
                # Add container name label
                - source_labels: [__meta_kubernetes_pod_container_name]
                  action: replace
                  target_label: container
                # Add node name label
                - source_labels: [__meta_kubernetes_pod_node_name]
                  action: replace
                  target_label: node
                # Add app label (prefer app, fallback to app.kubernetes.io/name)
                - source_labels: [__meta_kubernetes_pod_label_app]
                  action: replace
                  target_label: app
                - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
                  action: replace
                  target_label: app
                  regex: (.+)
                # Override app for Tailscale proxies (default app label is UUID)
                - source_labels: [__meta_kubernetes_pod_label_tailscale_com_parent_resource]
                  action: replace
                  target_label: app
                  regex: (.+)
                  replacement: ts-$1
                # Add component label
                - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_component]
                  action: replace
                  target_label: component
                  regex: (.+)
                # Set job to namespace/app for uniqueness
                - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_app]
                  action: replace
                  target_label: job
                  separator: /
                  regex: (.+/.+)
                - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_app_kubernetes_io_name]
                  action: replace
                  target_label: job
                  separator: /
                  regex: (.+/.+)
                # Override job for Tailscale proxies (default app label is UUID)
                - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_tailscale_com_parent_resource]
                  action: replace
                  target_label: job
                  separator: /ts-
                  regex: (.+/ts-.+)
                # Extra labels from annotations (prometheus.io/label-<name>)
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_label_cluster]
                  action: replace
                  target_label: k8s_cluster
                  regex: (.+)
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_label_environment]
                  action: replace
                  target_label: environment
                  regex: (.+)
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_label_service]
                  action: replace
                  target_label: service
                  regex: (.+)
              metric_relabel_configs:
                # Add k8s_cluster label to all metrics (avoids collision with CNPG's "cluster" label)
                - target_label: k8s_cluster
                  replacement: "do-nyc3-prod"
                  action: replace

      # Scrape kubelet cAdvisor metrics for container resource usage
      prometheus/kubelet:
        config:
          scrape_configs:
            - job_name: "kubelet-cadvisor"
              scrape_interval: 30s
              scheme: https
              kubernetes_sd_configs:
                - role: node
              authorization:
                credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: true
              relabel_configs:
                # Only scrape the local node
                - source_labels: [__meta_kubernetes_node_name]
                  action: keep
                  regex: ${env:K8S_NODE_NAME}
                # Use kubelet HTTPS endpoint
                - source_labels: [__meta_kubernetes_node_address_InternalIP]
                  action: replace
                  target_label: __address__
                  regex: (.+)
                  replacement: $1:10250
                # Scrape cAdvisor metrics endpoint
                - target_label: __metrics_path__
                  replacement: /metrics/cadvisor
                # Add node label
                - source_labels: [__meta_kubernetes_node_name]
                  action: replace
                  target_label: node
                # Set instance to node name for dashboard compatibility
                - source_labels: [__meta_kubernetes_node_name]
                  action: replace
                  target_label: instance
                # Set job label
                - target_label: job
                  replacement: kubelet
              metric_relabel_configs:
                # Add k8s_cluster label to all metrics (avoids collision with CNPG's "cluster" label)
                - target_label: k8s_cluster
                  replacement: "do-nyc3-prod"
                  action: replace

            # Scrape kubelet metrics (includes volume stats)
            - job_name: "kubelet"
              scrape_interval: 30s
              scheme: https
              kubernetes_sd_configs:
                - role: node
              authorization:
                credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: true
              relabel_configs:
                # Only scrape the local node
                - source_labels: [__meta_kubernetes_node_name]
                  action: keep
                  regex: ${env:K8S_NODE_NAME}
                # Use kubelet HTTPS endpoint
                - source_labels: [__meta_kubernetes_node_address_InternalIP]
                  action: replace
                  target_label: __address__
                  regex: (.+)
                  replacement: $1:10250
                # Add node label
                - source_labels: [__meta_kubernetes_node_name]
                  action: replace
                  target_label: node
                # Set instance to node name for dashboard compatibility
                - source_labels: [__meta_kubernetes_node_name]
                  action: replace
                  target_label: instance
                # Set job label
                - target_label: job
                  replacement: kubelet
              metric_relabel_configs:
                # Add k8s_cluster label to all metrics (avoids collision with CNPG's "cluster" label)
                - target_label: k8s_cluster
                  replacement: "do-nyc3-prod"
                  action: replace

      # Scrape Linkerd proxy metrics for linkerd-viz
      # These metrics power the linkerd viz stat/dashboard commands
      prometheus/linkerd:
        config:
          scrape_configs:
            - job_name: "linkerd-proxy"
              scrape_interval: 10s
              kubernetes_sd_configs:
                - role: pod
              relabel_configs:
                # Only scrape pods on this node
                - source_labels: [__meta_kubernetes_pod_node_name]
                  action: keep
                  regex: ${env:K8S_NODE_NAME}
                # Only scrape linkerd-proxy containers
                - source_labels: [__meta_kubernetes_pod_container_name]
                  action: keep
                  regex: linkerd-proxy
                # Only scrape linkerd-admin port
                - source_labels: [__meta_kubernetes_pod_container_port_name]
                  action: keep
                  regex: linkerd-admin
                # Add namespace label
                - source_labels: [__meta_kubernetes_namespace]
                  action: replace
                  target_label: namespace
                # Add pod name label
                - source_labels: [__meta_kubernetes_pod_name]
                  action: replace
                  target_label: pod
                # Add node name label
                - source_labels: [__meta_kubernetes_pod_node_name]
                  action: replace
                  target_label: node
                # Add app label for consistency with other scrape configs
                - source_labels: [__meta_kubernetes_pod_label_app]
                  action: replace
                  target_label: app
                - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
                  action: replace
                  target_label: app
                  regex: (.+)
                # Map Linkerd pod labels to metric labels
                # These are added by Linkerd injection and identify the source workload
                - source_labels: [__meta_kubernetes_pod_label_linkerd_io_proxy_deployment]
                  action: replace
                  target_label: deployment
                - source_labels: [__meta_kubernetes_pod_label_linkerd_io_proxy_daemonset]
                  action: replace
                  target_label: daemonset
                - source_labels: [__meta_kubernetes_pod_label_linkerd_io_proxy_statefulset]
                  action: replace
                  target_label: statefulset
                - source_labels: [__meta_kubernetes_pod_label_linkerd_io_proxy_job]
                  action: replace
                  target_label: k8s_job
                # Set job label for linkerd-viz compatibility
                - target_label: job
                  replacement: linkerd-proxy
              metric_relabel_configs:
                # Add k8s_cluster label to all metrics (avoids collision with CNPG's "cluster" label)
                - target_label: k8s_cluster
                  replacement: "do-nyc3-prod"
                  action: replace
                # Keep metrics required by linkerd-viz
                # These power the dashboard and CLI stats commands
                - source_labels: [__name__]
                  action: keep
                  regex: 'request_total|response_total|response_latency_ms_(bucket|count|sum)|tcp_.*'

      # Scrape kube-apiserver metrics
      # Note: etcd and kube-scheduler are NOT accessible in DOKS (managed by DigitalOcean)
      prometheus/apiserver:
        config:
          scrape_configs:
            - job_name: "kube-apiserver"
              scrape_interval: 30s
              scheme: https
              kubernetes_sd_configs:
                - role: endpoints
                  namespaces:
                    names: ["default"]
              authorization:
                credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: true
              relabel_configs:
                # Only scrape the kubernetes apiserver service
                - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
                  action: keep
                  regex: kubernetes;https
                # Set job label
                - target_label: job
                  replacement: kube-apiserver
              metric_relabel_configs:
                # Add k8s_cluster label to all metrics (avoids collision with CNPG's "cluster" label)
                - target_label: k8s_cluster
                  replacement: "do-nyc3-prod"
                  action: replace

    processors:
      batch:
        send_batch_size: 10000
        timeout: 10s

      memory_limiter:
        check_interval: 1s
        limit_mib: 400

      # Add resource attributes for better querying in Mimir
      # Note: Using k8s_cluster to avoid collision with CNPG's "cluster" label
      resource:
        attributes:
          - key: k8s_cluster
            value: do-nyc3-prod
            action: insert

    exporters:
      # Send metrics to Mimir via OTLP
      otlphttp/mimir:
        endpoint: "http://mimir-gateway.mimir.svc.cluster.local/otlp"
        headers:
          X-Scope-OrgID: "prod"
        # Retry configuration with jitter to prevent thundering herd
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 300s
          max_elapsed_time: 600s
          randomization_factor: 0.5
        # Sending queue for buffering during transient failures
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 5000

      # Debug exporter (disabled by default)
      debug:
        verbosity: basic

    service:
      telemetry:
        logs:
          level: info
        metrics:
          address: 0.0.0.0:8888
      pipelines:
        metrics/annotations:
          receivers: [prometheus/annotations]
          processors: [memory_limiter, resource, batch]
          exporters: [otlphttp/mimir]

        metrics/ports:
          receivers: [prometheus/ports]
          processors: [memory_limiter, resource, batch]
          exporters: [otlphttp/mimir]

        metrics/kubelet:
          receivers: [prometheus/kubelet]
          processors: [memory_limiter, resource, batch]
          exporters: [otlphttp/mimir]

        metrics/apiserver:
          receivers: [prometheus/apiserver]
          processors: [memory_limiter, resource, batch]
          exporters: [otlphttp/mimir]

        metrics/linkerd:
          receivers: [prometheus/linkerd]
          processors: [memory_limiter, resource, batch]
          exporters: [otlphttp/mimir]

  # Environment variables for node-local scraping
  extraEnvs:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
